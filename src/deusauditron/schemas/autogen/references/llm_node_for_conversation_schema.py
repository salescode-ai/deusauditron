# generated by datamodel-codegen:
#   filename:  references/llm_node_for_conversation.schema.json

from __future__ import annotations

from enum import Enum
from typing import Optional

from .llm_node_schema import LLMNodeConfig


class GlobalCodeNodeExecutionStage(Enum):
    with_llm = "with_llm"
    before_llm = "before_llm"
    after_llm = "after_llm"


class LLMNodeForConversation(LLMNodeConfig):
    global_code_node_execution_stage: Optional[GlobalCodeNodeExecutionStage] = None
    skip_intent_upon_interruption: Optional[bool] = False
